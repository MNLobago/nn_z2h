{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# picking up at contexts to tell or predict what comes after the inputed contexts...\n",
    "# splitlines turns the texts into an array\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a dictionary that maintains counts for\n",
    "# learning the statistics by counting how often combinations occur in a data set... like we are taking the contexts in pair and are checking our dataset to count their occurrence\n",
    "\n",
    "# it is like we are trying to determine whatever comes next by figuring out what comes before; just that we are primarily pairing them together first.\n",
    "# then counting their occurence\n",
    "\n",
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    # zip does the normal perfoliating\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        # the pair up\n",
    "        bigram = (ch1, ch2)\n",
    "        # the hook bigram as a key and turned into a unique tuple again using get\n",
    "        b[bigram] = b.get(bigram, 0) + 1\n",
    "        # print(ch1, ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S>', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '<E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S>', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '<E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S>', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '<E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S>', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S>', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S>', 'l'), 1572),\n",
       " (('<S>', 'c'), 1542),\n",
       " (('<S>', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '<E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '<E>'), 1314),\n",
       " (('<S>', 't'), 1308),\n",
       " (('<S>', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '<E>'), 1169),\n",
       " (('<S>', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S>', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S>', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '<E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S>', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S>', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S>', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '<E>'), 516),\n",
       " (('d', '<E>'), 516),\n",
       " (('<S>', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '<E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S>', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S>', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S>', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '<E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S>', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '<E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '<E>'), 160),\n",
       " (('u', '<E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S>', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '<E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '<E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '<E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S>', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '<E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '<E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S>', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '<E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '<E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '<E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '<E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case b is assumed to have the statistics of the whole dataset.... By measure of calculating the counts of all the bigrams/pairs and getting how often they occur. \n",
    "b\n",
    "\n",
    "# sort from the dictionary\n",
    "sorted(b.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets store the info into a 2-dimensional array tensor\n",
    "#  using torch\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples: 228146\n"
     ]
    }
   ],
   "source": [
    "# FULL SUMMARIZATION\n",
    "\n",
    "# create the dataset\n",
    "# the data size \n",
    "dsize = len(stoi)\n",
    "# let us tokenize the data by going through these transformations\n",
    "N = torch.zeros((dsize, dsize), dtype=torch.int32)\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "        N[ix1, ix2] += 1\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(f'number of examples: {num}')\n",
    "\n",
    "\n",
    "# initialize the 'network'\n",
    "g= torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((dsize, dsize), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1192e-05, 1.3759e-01, 4.0767e-02, 4.8129e-02, 5.2745e-02, 4.7785e-02,\n",
       "         1.3038e-02, 2.0898e-02, 2.7293e-02, 1.8465e-02, 7.5577e-02, 9.2452e-02,\n",
       "         4.9064e-02, 7.9195e-02, 3.5777e-02, 1.2321e-02, 1.6095e-02, 2.9008e-03,\n",
       "         5.1154e-02, 6.4130e-02, 4.0830e-02, 2.4641e-03, 1.1759e-02, 9.6070e-03,\n",
       "         4.2109e-03, 1.6719e-02, 2.9008e-02],\n",
       "        [1.9583e-01, 1.6425e-02, 1.5983e-02, 1.3889e-02, 3.0756e-02, 2.0435e-02,\n",
       "         3.9809e-03, 4.9835e-03, 6.8796e-02, 4.8685e-02, 5.1899e-03, 1.6779e-02,\n",
       "         7.4575e-02, 4.8213e-02, 1.6039e-01, 1.8872e-03, 2.4475e-03, 1.7988e-03,\n",
       "         9.6279e-02, 3.2997e-02, 2.0288e-02, 1.1264e-02, 2.4623e-02, 4.7771e-03,\n",
       "         5.3963e-03, 6.0480e-02, 1.2857e-02],\n",
       "        [4.3039e-02, 1.2051e-01, 1.4596e-02, 7.4850e-04, 2.4701e-02, 2.4551e-01,\n",
       "         3.7425e-04, 3.7425e-04, 1.5719e-02, 8.1587e-02, 7.4850e-04, 3.7425e-04,\n",
       "         3.8922e-02, 3.7425e-04, 1.8713e-03, 3.9671e-02, 3.7425e-04, 3.7425e-04,\n",
       "         3.1549e-01, 3.3683e-03, 1.1228e-03, 1.7216e-02, 3.7425e-04, 3.7425e-04,\n",
       "         3.7425e-04, 3.1437e-02, 3.7425e-04],\n",
       "        [2.7536e-02, 2.2928e-01, 2.8098e-04, 1.2082e-02, 5.6196e-04, 1.5510e-01,\n",
       "         2.8098e-04, 8.4293e-04, 1.8685e-01, 7.6426e-02, 1.1239e-03, 8.9070e-02,\n",
       "         3.2874e-02, 2.8098e-04, 2.8098e-04, 1.0705e-01, 5.6196e-04, 3.3717e-03,\n",
       "         2.1635e-02, 1.6859e-03, 1.0115e-02, 1.0115e-02, 2.8098e-04, 2.8098e-04,\n",
       "         1.1239e-03, 2.9503e-02, 1.4049e-03],\n",
       "        [9.3609e-02, 2.3610e-01, 3.6212e-04, 7.2424e-04, 2.7159e-02, 2.3248e-01,\n",
       "         1.0864e-03, 4.7076e-03, 2.1546e-02, 1.2222e-01, 1.8106e-03, 7.2424e-04,\n",
       "         1.1045e-02, 5.6129e-03, 5.7940e-03, 6.8622e-02, 1.8106e-04, 3.6212e-04,\n",
       "         7.6951e-02, 5.4318e-03, 9.0531e-04, 1.6839e-02, 3.2591e-03, 4.3455e-03,\n",
       "         1.8106e-04, 5.7577e-02, 3.6212e-04],\n",
       "        [1.9482e-01, 3.3252e-02, 5.9658e-03, 7.5306e-03, 1.8826e-02, 6.2200e-02,\n",
       "         4.0587e-03, 6.1614e-03, 7.4817e-03, 4.0049e-02, 2.7384e-03, 8.7531e-03,\n",
       "         1.5888e-01, 3.7653e-02, 1.3086e-01, 1.3203e-02, 4.1076e-03, 7.3350e-04,\n",
       "         9.5795e-02, 4.2152e-02, 2.8411e-02, 3.4230e-03, 2.2689e-02, 2.4939e-03,\n",
       "         6.5037e-03, 5.2372e-02, 8.8998e-03],\n",
       "        [8.6910e-02, 2.6073e-01, 1.0730e-03, 1.0730e-03, 1.0730e-03, 1.3305e-01,\n",
       "         4.8283e-02, 2.1459e-03, 2.1459e-03, 1.7275e-01, 1.0730e-03, 3.2189e-03,\n",
       "         2.2532e-02, 1.0730e-03, 5.3648e-03, 6.5451e-02, 1.0730e-03, 1.0730e-03,\n",
       "         1.2339e-01, 7.5107e-03, 2.0386e-02, 1.1803e-02, 1.0730e-03, 5.3648e-03,\n",
       "         1.0730e-03, 1.6094e-02, 3.2189e-03],\n",
       "        [5.5783e-02, 1.6940e-01, 2.0471e-03, 5.1177e-04, 1.0235e-02, 1.7144e-01,\n",
       "         1.0235e-03, 1.3306e-02, 1.8475e-01, 9.7748e-02, 2.0471e-03, 5.1177e-04,\n",
       "         1.6888e-02, 3.5824e-03, 1.4330e-02, 4.2989e-02, 5.1177e-04, 5.1177e-04,\n",
       "         1.0338e-01, 1.5865e-02, 1.6377e-02, 4.4012e-02, 1.0235e-03, 1.3818e-02,\n",
       "         5.1177e-04, 1.6377e-02, 1.0235e-03],\n",
       "        [3.1532e-01, 2.9373e-01, 1.1775e-03, 3.9252e-04, 3.2710e-03, 8.8316e-02,\n",
       "         3.9252e-04, 3.9252e-04, 2.6168e-04, 9.5512e-02, 1.3084e-03, 3.9252e-03,\n",
       "         2.4336e-02, 1.5439e-02, 1.8187e-02, 3.7682e-02, 2.6168e-04, 2.6168e-04,\n",
       "         2.6822e-02, 4.1868e-03, 9.4204e-03, 2.1850e-02, 5.2335e-03, 1.4392e-03,\n",
       "         1.3084e-04, 2.7999e-02, 2.7476e-03],\n",
       "        [1.4046e-01, 1.3797e-01, 6.2613e-03, 2.8768e-02, 2.4876e-02, 9.3299e-02,\n",
       "         5.7536e-03, 2.4199e-02, 5.4152e-03, 4.6819e-03, 4.3434e-03, 2.5158e-02,\n",
       "         7.5925e-02, 2.4143e-02, 1.1998e-01, 3.3224e-02, 3.0460e-03, 2.9896e-03,\n",
       "         4.7947e-02, 7.4289e-02, 3.0573e-02, 6.2049e-03, 1.5230e-02, 5.0767e-04,\n",
       "         5.0767e-03, 4.3998e-02, 1.5681e-02],\n",
       "        [2.4599e-02, 5.0359e-01, 6.8329e-04, 1.7082e-03, 1.7082e-03, 1.5067e-01,\n",
       "         3.4165e-04, 3.4165e-04, 1.5716e-02, 4.0998e-02, 1.0249e-03, 1.0249e-03,\n",
       "         3.4165e-03, 2.0499e-03, 1.0249e-03, 1.6399e-01, 6.8329e-04, 3.4165e-04,\n",
       "         4.0998e-03, 2.7332e-03, 1.0249e-03, 6.9354e-02, 2.0499e-03, 2.3915e-03,\n",
       "         3.4165e-04, 3.7581e-03, 3.4165e-04],\n",
       "        [7.1837e-02, 3.4182e-01, 5.9207e-04, 5.9207e-04, 5.9207e-04, 1.7683e-01,\n",
       "         3.9471e-04, 1.9736e-04, 6.0785e-02, 1.0065e-01, 5.9207e-04, 4.1445e-03,\n",
       "         2.7630e-02, 1.9736e-03, 5.3286e-03, 6.8088e-02, 1.9736e-04, 1.9736e-04,\n",
       "         2.1709e-02, 1.8946e-02, 3.5524e-03, 1.0065e-02, 5.9207e-04, 6.9074e-03,\n",
       "         1.9736e-04, 7.4995e-02, 5.9207e-04],\n",
       "        [9.4029e-02, 1.8763e-01, 3.7898e-03, 1.8591e-03, 9.9392e-03, 2.0894e-01,\n",
       "         1.6446e-03, 5.0054e-04, 1.4301e-03, 1.7740e-01, 5.0054e-04, 1.7876e-03,\n",
       "         9.6246e-02, 4.3618e-03, 1.0726e-03, 4.9553e-02, 1.1441e-03, 2.8602e-04,\n",
       "         1.3586e-03, 6.7930e-03, 5.5774e-03, 2.3239e-02, 5.2199e-03, 1.2156e-03,\n",
       "         7.1505e-05, 1.1362e-01, 7.8656e-04],\n",
       "        [7.7523e-02, 3.8851e-01, 1.6944e-02, 7.7973e-03, 3.7487e-03, 1.2281e-01,\n",
       "         2.9990e-04, 1.4995e-04, 8.9969e-04, 1.8848e-01, 1.1996e-03, 2.9990e-04,\n",
       "         8.9969e-04, 2.5341e-02, 3.1489e-03, 6.7926e-02, 5.8480e-03, 1.4995e-04,\n",
       "         1.4695e-02, 5.3981e-03, 7.4974e-04, 2.0993e-02, 5.9979e-04, 4.4984e-04,\n",
       "         1.4995e-04, 4.3185e-02, 1.7994e-03],\n",
       "        [3.6853e-01, 1.6225e-01, 4.9036e-04, 1.1660e-02, 3.8411e-02, 7.4098e-02,\n",
       "         6.5381e-04, 1.4929e-02, 1.4711e-03, 9.4039e-02, 2.4518e-03, 3.2146e-03,\n",
       "         1.0679e-02, 1.0897e-03, 1.0390e-01, 2.7079e-02, 3.2690e-04, 1.6345e-04,\n",
       "         2.4518e-03, 1.5201e-02, 2.4191e-02, 5.2850e-03, 3.0511e-03, 6.5381e-04,\n",
       "         3.8139e-04, 2.5390e-02, 7.9547e-03],\n",
       "        [1.0752e-01, 1.8842e-02, 1.7711e-02, 1.4445e-02, 2.3992e-02, 1.6706e-02,\n",
       "         4.3964e-03, 5.6526e-03, 2.1605e-02, 8.7929e-03, 2.1354e-03, 8.6673e-03,\n",
       "         7.7880e-02, 3.2910e-02, 3.0298e-01, 1.4571e-02, 1.2059e-02, 5.0245e-04,\n",
       "         1.3315e-01, 6.3434e-02, 1.4948e-02, 3.4669e-02, 2.2233e-02, 1.4445e-02,\n",
       "         5.7782e-03, 1.3064e-02, 6.9087e-03],\n",
       "        [3.2289e-02, 1.9943e-01, 2.8490e-03, 1.8993e-03, 9.4967e-04, 1.8803e-01,\n",
       "         1.8993e-03, 9.4967e-04, 1.9468e-01, 5.8879e-02, 1.8993e-03, 1.8993e-03,\n",
       "         1.6144e-02, 1.8993e-03, 1.8993e-03, 5.6980e-02, 3.7987e-02, 9.4967e-04,\n",
       "         1.4435e-01, 1.6144e-02, 1.7094e-02, 4.7483e-03, 9.4967e-04, 9.4967e-04,\n",
       "         9.4967e-04, 1.2346e-02, 9.4967e-04],\n",
       "        [9.6990e-02, 4.6823e-02, 3.3445e-03, 3.3445e-03, 3.3445e-03, 6.6890e-03,\n",
       "         3.3445e-03, 3.3445e-03, 3.3445e-03, 4.6823e-02, 3.3445e-03, 3.3445e-03,\n",
       "         6.6890e-03, 1.0033e-02, 3.3445e-03, 1.0033e-02, 3.3445e-03, 3.3445e-03,\n",
       "         6.6890e-03, 1.0033e-02, 3.3445e-03, 6.9231e-01, 3.3445e-03, 1.3378e-02,\n",
       "         3.3445e-03, 3.3445e-03, 3.3445e-03],\n",
       "        [1.0827e-01, 1.8520e-01, 3.3001e-03, 7.8573e-03, 1.4772e-02, 1.3342e-01,\n",
       "         7.8573e-04, 6.0501e-03, 9.5859e-03, 2.3839e-01, 2.0429e-03, 7.1502e-03,\n",
       "         3.2529e-02, 1.2807e-02, 1.1079e-02, 6.8359e-02, 1.1786e-03, 1.3357e-03,\n",
       "         3.3472e-02, 1.5007e-02, 1.6422e-02, 1.9879e-02, 6.3644e-03, 1.7286e-03,\n",
       "         3.1429e-04, 6.0816e-02, 1.8858e-03],\n",
       "        [1.4386e-01, 1.4779e-01, 2.7050e-03, 7.5003e-03, 1.2296e-03, 1.0882e-01,\n",
       "         3.6887e-04, 3.6887e-04, 1.5812e-01, 8.4225e-02, 3.6887e-04, 1.0205e-02,\n",
       "         3.4428e-02, 1.1189e-02, 3.0739e-03, 6.5413e-02, 6.3937e-03, 2.4591e-04,\n",
       "         6.8855e-03, 5.6806e-02, 9.4184e-02, 2.2870e-02, 1.8443e-03, 3.0739e-03,\n",
       "         1.2296e-04, 2.6558e-02, 1.3525e-03],\n",
       "        [8.6475e-02, 1.8367e-01, 3.5733e-04, 3.2160e-03, 1.7867e-04, 1.2810e-01,\n",
       "         5.3600e-04, 5.3600e-04, 1.1578e-01, 9.5230e-02, 7.1467e-04, 1.7867e-04,\n",
       "         2.4120e-02, 8.9334e-04, 4.1093e-03, 1.1935e-01, 1.7867e-04, 1.7867e-04,\n",
       "         6.3070e-02, 6.4320e-03, 6.7000e-02, 1.4115e-02, 2.8587e-03, 2.1440e-03,\n",
       "         5.3600e-04, 6.1104e-02, 1.8939e-02],\n",
       "        [4.9336e-02, 5.1866e-02, 3.2891e-02, 3.2891e-02, 4.3327e-02, 5.3763e-02,\n",
       "         6.3251e-03, 1.5180e-02, 1.8659e-02, 3.8583e-02, 4.7438e-03, 2.9728e-02,\n",
       "         9.5509e-02, 4.9020e-02, 8.7287e-02, 3.4788e-03, 5.3763e-03, 3.4788e-03,\n",
       "         1.3125e-01, 1.5022e-01, 2.6249e-02, 1.2650e-03, 1.2018e-02, 2.7514e-02,\n",
       "         1.1069e-02, 4.4276e-03, 1.4548e-02],\n",
       "        [3.4231e-02, 2.4731e-01, 7.6923e-04, 3.8462e-04, 7.6923e-04, 2.1885e-01,\n",
       "         3.8462e-04, 3.8462e-04, 7.6923e-04, 3.5077e-01, 3.8462e-04, 1.5385e-03,\n",
       "         5.7692e-03, 3.8462e-04, 3.4615e-03, 5.9231e-02, 3.8462e-04, 3.8462e-04,\n",
       "         1.8846e-02, 3.8462e-04, 3.8462e-04, 3.0769e-03, 3.0769e-03, 3.8462e-04,\n",
       "         3.8462e-04, 4.6923e-02, 3.8462e-04],\n",
       "        [5.4393e-02, 2.9393e-01, 2.0921e-03, 1.0460e-03, 9.4142e-03, 1.5690e-01,\n",
       "         3.1381e-03, 2.0921e-03, 2.5105e-02, 1.5586e-01, 1.0460e-03, 7.3222e-03,\n",
       "         1.4644e-02, 3.1381e-03, 6.1715e-02, 3.8703e-02, 1.0460e-03, 1.0460e-03,\n",
       "         2.4059e-02, 2.1967e-02, 9.4142e-03, 2.7197e-02, 1.0460e-03, 3.1381e-03,\n",
       "         1.0460e-03, 7.7406e-02, 2.0921e-03],\n",
       "        [2.2790e-01, 1.4365e-01, 2.7624e-03, 6.9061e-03, 8.2873e-03, 5.1105e-02,\n",
       "         5.5249e-03, 1.3812e-03, 2.7624e-03, 1.4227e-01, 1.3812e-03, 1.3812e-03,\n",
       "         5.5249e-02, 2.7624e-03, 2.7624e-03, 5.8011e-02, 1.3812e-03, 1.3812e-03,\n",
       "         1.3812e-03, 4.4199e-02, 9.8066e-02, 8.2873e-03, 1.3812e-03, 5.5249e-03,\n",
       "         5.3867e-02, 4.2818e-02, 2.7624e-02],\n",
       "        [2.0484e-01, 2.1871e-01, 2.8563e-03, 1.1833e-02, 2.7849e-02, 3.0807e-02,\n",
       "         1.3261e-03, 3.1623e-03, 2.3462e-03, 1.9688e-02, 2.4482e-03, 8.8748e-03,\n",
       "         1.1272e-01, 1.5199e-02, 1.8637e-01, 2.7747e-02, 1.6322e-03, 7.1407e-04,\n",
       "         2.9787e-02, 4.1008e-02, 1.0711e-02, 1.4485e-02, 1.0915e-02, 5.1005e-04,\n",
       "         2.9583e-03, 2.4482e-03, 8.0588e-03],\n",
       "        [6.6392e-02, 3.5505e-01, 2.0619e-03, 1.2371e-03, 1.2371e-03, 1.5423e-01,\n",
       "         4.1237e-04, 8.2474e-04, 1.8144e-02, 1.5052e-01, 1.2371e-03, 1.2371e-03,\n",
       "         5.1134e-02, 1.4845e-02, 2.0619e-03, 4.5773e-02, 1.2371e-03, 4.1237e-04,\n",
       "         1.3608e-02, 2.0619e-03, 2.0619e-03, 3.0515e-02, 1.2371e-03, 1.6495e-03,\n",
       "         8.2474e-04, 6.1031e-02, 1.8969e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us tokenize the data by going through these transformations\n",
    "P = (N + 1).float()\n",
    "P = P/P.sum(1, keepdim=True)\n",
    "P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.768618583679199\n",
      "3.3788068294525146\n",
      "3.161090850830078\n",
      "3.0271859169006348\n",
      "2.9344842433929443\n",
      "2.867231607437134\n",
      "2.8166542053222656\n",
      "2.777146577835083\n",
      "2.745253801345825\n",
      "2.7188305854797363\n",
      "2.696505308151245\n",
      "2.6773719787597656\n",
      "2.6608052253723145\n",
      "2.6463515758514404\n",
      "2.633665084838867\n",
      "2.622471570968628\n",
      "2.6125476360321045\n",
      "2.6037068367004395\n",
      "2.595794916152954\n",
      "2.5886807441711426\n",
      "2.5822560787200928\n",
      "2.576429843902588\n",
      "2.5711236000061035\n",
      "2.566272735595703\n",
      "2.5618226528167725\n",
      "2.5577261447906494\n",
      "2.5539441108703613\n",
      "2.550442695617676\n",
      "2.5471930503845215\n",
      "2.5441699028015137\n",
      "2.5413522720336914\n",
      "2.538722038269043\n",
      "2.536262035369873\n",
      "2.5339579582214355\n",
      "2.531797409057617\n",
      "2.529768228530884\n",
      "2.527860164642334\n",
      "2.5260636806488037\n",
      "2.5243704319000244\n",
      "2.522773265838623\n",
      "2.52126407623291\n",
      "2.519836664199829\n",
      "2.5184857845306396\n",
      "2.5172054767608643\n",
      "2.515990734100342\n",
      "2.5148372650146484\n",
      "2.5137407779693604\n",
      "2.512697696685791\n",
      "2.511704921722412\n",
      "2.5107579231262207\n",
      "2.509855031967163\n",
      "2.5089924335479736\n",
      "2.5081679821014404\n",
      "2.507380485534668\n",
      "2.5066258907318115\n",
      "2.5059030055999756\n",
      "2.5052103996276855\n",
      "2.5045459270477295\n",
      "2.503908157348633\n",
      "2.503295421600342\n",
      "2.5027060508728027\n",
      "2.5021398067474365\n",
      "2.501594305038452\n",
      "2.5010695457458496\n",
      "2.500563383102417\n",
      "2.500075578689575\n",
      "2.4996049404144287\n",
      "2.499150514602661\n",
      "2.4987120628356934\n",
      "2.49828839302063\n",
      "2.4978787899017334\n",
      "2.4974827766418457\n",
      "2.4970996379852295\n",
      "2.4967293739318848\n",
      "2.496370315551758\n",
      "2.4960227012634277\n",
      "2.4956860542297363\n",
      "2.4953596591949463\n",
      "2.4950432777404785\n",
      "2.494736433029175\n",
      "2.494438886642456\n",
      "2.494149684906006\n",
      "2.4938690662384033\n",
      "2.4935965538024902\n",
      "2.4933321475982666\n",
      "2.493075132369995\n",
      "2.4928252696990967\n",
      "2.492582321166992\n",
      "2.4923462867736816\n",
      "2.492116689682007\n",
      "2.4918932914733887\n",
      "2.491675853729248\n",
      "2.491464376449585\n",
      "2.491258382797241\n",
      "2.491057872772217\n",
      "2.4908623695373535\n",
      "2.4906723499298096\n",
      "2.4904870986938477\n",
      "2.4903063774108887\n",
      "2.4901304244995117\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=dsize).float() # input to the network: one-hot encoding REMEMBER TO CAST AS FLOAT\n",
    "    logits = xenc @ W # predict log-counts using the matrix multiplier\n",
    "    # the next two lines are the softmax\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdim=True) # probabilities for the next character || Whenever you are normalizing always remember to preserve the dimension\n",
    "    # normal loss\n",
    "    # loss = -probs[torch.arange(num), ys].log().mean() \n",
    "    # adding a regularization to the loss so that the loss does not accumulate too much if the weoghts are greater than one; and the loss is zero if the w is 0 >>> adding like a gravity force that makes W 0\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update the weight\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cfay.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "# sample from the 'neural net' model\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # ---------\n",
    "        # Before\n",
    "        # p = P[ix]\n",
    "        # --------\n",
    "        # Now\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W # predict log counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        # --------\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = torch.Generator().manual_seed(23412342342334)\n",
    "# m = torch.rand(2, generator=g)\n",
    "# m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = torch.multinomial(m, num_samples=20, replacement=True, generator=g)\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.one_hot(k, num_classes=4).float()\n",
    "# torch.tensor([2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchlight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
